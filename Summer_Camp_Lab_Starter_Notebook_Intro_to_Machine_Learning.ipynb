{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Summer Camp Lab 1 - Intro to Machine Learning\n",
        "\n",
        "In this lab we will practice:\n",
        "\n",
        "* Loading Data\n",
        "* Data Exploration\n",
        "* Selecting the Prediction Target\n",
        "* Choosing Features\n",
        "* Splitting Data into Training and Test Sets\n",
        "* Building a Decision Tree Model\n",
        "* Model Validation\n",
        "* Hyperparameter Tuning\n",
        "* Building a Random Forest Model\n"
      ],
      "metadata": {
        "id": "83e8WGupd2Lb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up the Workspace"
      ],
      "metadata": {
        "id": "O_bQwf8uCCWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas==2.0.3 scikit-learn=1.2.2 matplotlib==3.7.1"
      ],
      "metadata": {
        "id": "PiV240DdBz-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "kOySuqgH4TgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case Study\n",
        "\n",
        "BigMart's team of data scientists has gathered sales data for the year 2013, encompassing 1559 products distributed across 10 stores situated in various cities. The dataset includes specific attributes for each product and store.\n",
        "\n",
        "The primary objective is to construct a predictive model capable of forecasting the sales of individual products within specific outlets.\n",
        "\n",
        "This predictive model aims to unveil the influential factors that contribute to increased sales, enabling BigMart to gain insights into product and outlet characteristics crucial for sales growth."
      ],
      "metadata": {
        "id": "lJ1zOHJh4ZIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data has the following features that could be useful in your model:\n",
        "\n",
        "* Item_Identifier: A unique identifier for each product.\n",
        "\n",
        "* Item_Weight: The weight of the product.\n",
        "\n",
        "* Item_Fat_Content: Indicates the level of fat content in the product, often categorized as 'Low Fat,' 'Regular,' etc.\n",
        "\n",
        "* Item_Visibility: The percentage of total display area of all products in a store allocated to a particular product.\n",
        "\n",
        "* Item_Type: The category or type of the product (e.g., dairy, meat, fruits, etc.).\n",
        "\n",
        "* Item_MRP (Maximum Retail Price): The maximum price at which the product can be sold.\n",
        "\n",
        "* Outlet_Identifier: A unique identifier for each store/outlet.\n",
        "\n",
        "* Outlet_Establishment_Year: The year in which the store was established.\n",
        "\n",
        "* Outlet_Size: The size of the store, often categorized as 'Small,' 'Medium,' or 'Large.'\n",
        "\n",
        "* Outlet_Location_Type: The type of location where the store is situated, such as 'Urban,' 'Suburban,' or 'Rural.'\n",
        "\n",
        "* Outlet_Type: The type of outlet, such as 'Supermarket Type1,' 'Supermarket Type2,' 'Grocery Store,' etc.\n",
        "\n",
        "* Item_Outlet_Sales: The target variable, representing the sales of the product in a particular store.\n"
      ],
      "metadata": {
        "id": "-LilGM_1o5he"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Data"
      ],
      "metadata": {
        "id": "lDKUPq_gCXfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import pandas as pd\n",
        "df_sales = pd.read_csv('https://www.dropbox.com/s/yqaymhdf7bvvair/bigmart_sales_predictions.csv?dl=1')\n"
      ],
      "metadata": {
        "id": "1olkYpeKnlEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration"
      ],
      "metadata": {
        "id": "A7_8InxaJ-rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display first 5 rows of data\n",
        "df_sales.___"
      ],
      "metadata": {
        "id": "KffxRZpE4-dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# explore last 5 rows of data\n",
        "df_sales.___"
      ],
      "metadata": {
        "id": "ej6b-8leClxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display information about columns (non-null count and dtype)\n",
        "df_sales.___"
      ],
      "metadata": {
        "id": "YpcwBpXuDWcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# explore descriptive statistics of the numerical data\n",
        "df_sales.___"
      ],
      "metadata": {
        "id": "Ot_XYakUFVvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# explore values of object data, such as Outlet_Location_Type\n",
        "df_sales.___"
      ],
      "metadata": {
        "id": "7GhTOY6UHz68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting the Prediction Target"
      ],
      "metadata": {
        "id": "ZdD3SJ0KrG6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Our target variable is the sales of an item at an outlet.\n",
        "y = ___\n",
        "y"
      ],
      "metadata": {
        "id": "xRgznLASEg-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choosing Features"
      ],
      "metadata": {
        "id": "107Ec2NaEiGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We include a few features that we think could be useful as features in our model.\n",
        "#Include Item_Visibility. Item_MRP, Item_Weight\n",
        "X = df_sales[].fillna(0)\n",
        "X"
      ],
      "metadata": {
        "id": "Ixqs6iKCrEN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check descriptive statistics of the features\n",
        "X.___"
      ],
      "metadata": {
        "id": "XoUup4qSI67T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dtypes of the features\n",
        "X.___"
      ],
      "metadata": {
        "id": "z7JEpPwXI_Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data into Training and Test Sets\n",
        "\n",
        "Use random state if you want to generate the same split for each run of your code."
      ],
      "metadata": {
        "id": "4i5klzaorjsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the features and the target into training and test sets\n",
        "X_train, X_test, y_train, y_test = ___"
      ],
      "metadata": {
        "id": "w_BPnVM2rnfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Decision Tree Model"
      ],
      "metadata": {
        "id": "KiRgqjWAush-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a decision tree regressor\n",
        "model = ____()\n",
        "\n",
        "# Train the model\n",
        "model.fit(___)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(____)\n",
        "\n",
        "# Evaluate the model with mean_squared_error\n",
        "print(____)\n"
      ],
      "metadata": {
        "id": "iKelMjCJuuJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Validation"
      ],
      "metadata": {
        "id": "b7qdncSDKdbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean Absoulute Error (MAE)\n",
        "print(___(y_test, predictions))"
      ],
      "metadata": {
        "id": "k50LB0FEL381"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean Absoulute Percentage Error (MAPE)\n",
        "\n",
        "print(___(y_test, predictions))"
      ],
      "metadata": {
        "id": "SRA4MW3cL6eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean Squared Error (MSE)\n",
        "print(____(y_test, predictions))"
      ],
      "metadata": {
        "id": "WNO4SLI6L8_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Root Mean Squared Error (RMSE)\n",
        "print(___(y_test, predictions, ___))"
      ],
      "metadata": {
        "id": "Cvv02VNpL-IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "SQ29pEBZKuXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decisiontree_depth_effect(train_X, train_y, test_X, test_y, max_depth_range):\n",
        "\n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "\n",
        "    for depth in max_depth_range:\n",
        "        # Create a decision tree regressor with the specified maximum depth\n",
        "        model = DecisionTreeRegressor(max_depth=depth)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(train_X, train_y)\n",
        "\n",
        "        # Make predictions on training and test data\n",
        "        train_preds = model.predict(train_X)\n",
        "        test_preds = model.predict(test_X)\n",
        "\n",
        "        # Calculate mean squared error for training and test data\n",
        "        train_error = mean_squared_error(train_y, train_preds)\n",
        "        test_error = mean_squared_error(test_y, test_preds)\n",
        "\n",
        "        # Append errors to the lists\n",
        "        train_errors.append(train_error)\n",
        "        test_errors.append(test_error)\n",
        "\n",
        "    # Plotting the results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(max_depth_range, train_errors, label='Training Error', marker='o')\n",
        "    plt.plot(max_depth_range, test_errors, label='Test Error', marker='o')\n",
        "    plt.xlabel('Tree Depth')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.title('Effect of Tree Depth of DecisionTree on Error Metric')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "wLeSULS0KrdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display loss curves for a range of the hyperparameter\n",
        "decisiontree_depth_effect(X_train, y_train, X_test, y_test, range(___, ___))"
      ],
      "metadata": {
        "id": "QpaPUNOhK3Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Random Forest Model"
      ],
      "metadata": {
        "id": "F_A-XtWvuxbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a decision tree regressor\n",
        "model = ___()\n",
        "\n",
        "# Train the model\n",
        "model.___(___, ___)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.___(__)\n",
        "\n",
        "# Evaluate the model using MSE\n",
        "print(___(___, ___))"
      ],
      "metadata": {
        "id": "sH4isNPLuzhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def randomforest_depth_effect(train_X, train_y, test_X, test_y, max_depth_range):\n",
        "\n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "\n",
        "    for depth in max_depth_range:\n",
        "        # Create a decision tree regressor with the specified maximum depth\n",
        "        model = RandomForestRegressor(max_depth=depth)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(train_X, train_y)\n",
        "\n",
        "        # Make predictions on training and test data\n",
        "        train_preds = model.predict(train_X)\n",
        "        test_preds = model.predict(test_X)\n",
        "\n",
        "        # Calculate mean squared error for training and test data\n",
        "        train_error = mean_squared_error(train_y, train_preds)\n",
        "        test_error = mean_squared_error(test_y, test_preds)\n",
        "\n",
        "        # Append errors to the lists\n",
        "        train_errors.append(train_error)\n",
        "        test_errors.append(test_error)\n",
        "\n",
        "    # Plotting the results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(max_depth_range, train_errors, label='Training Error', marker='o')\n",
        "    plt.plot(max_depth_range, test_errors, label='Test Error', marker='o')\n",
        "    plt.xlabel('Tree Depth')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.title('Effect of Tree Depth of RandomForest on Error Metric')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "A_ZQ4B4kjBO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display loss curves for a range of the hyperparameter\n",
        "randomforest_depth_effect(X_train, y_train, X_test, y_test, range(___, ___))"
      ],
      "metadata": {
        "id": "ui_o1nSNjESf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Assignment\n",
        "\n",
        "In class you learned about the hyperparameter 'max_leaf_nodes'. In lab you learned about the hyperparameter 'max_depth'. Please repeat the lab notebook two (2) times experimenting with tuning the following hyperparamaters:\n",
        "\n",
        "* 'min_samples_split' (int, default=2): The minimum number of samples required to split an internal node.\n",
        "\n",
        "* 'min_samples_leaf' (int, default=1): The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
        "\n",
        "Does your tuning of the new hyperparametes yield \"better\" results than in lab? Explain your intuition why or why not.\n",
        "\n",
        "Please submit your two (2) notebooks together with a PDF file with brief interpretation of your findings.\n",
        "\n",
        "*The goal of the exercise is not to develop an optimal model, but rather to practice your skills and your reasoning.*\n",
        "\n",
        "\n",
        "BONUS: Experiment with adding a **categorical variable** as a series of binary dummy variables using techniques that you learned in Logistic Regression!"
      ],
      "metadata": {
        "id": "WK-L-rgJX5Fe"
      }
    }
  ]
}